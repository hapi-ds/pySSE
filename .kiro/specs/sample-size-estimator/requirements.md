# Requirements Document

## Introduction

The Sample Size Estimator is a Python-based web application designed to determine statistically valid sample sizes for medical device design verification and process validation. The system provides a user-friendly interface for advanced stochastic models and is critical for Quality Management Systems (QMS) to ensure compliance with risk-based statistical rationale requirements per ISO/TR 80002-2.

The application supports four primary statistical analysis modules:
- Attribute Data Analysis (binary outcomes)
- Variable Data Analysis (continuous measurements)
- Non-Normal Data Handling (transformations and non-parametric methods)
- Reliability Life Testing (time-dependent analysis)

## Glossary

- **System**: The Sample Size Estimator application
- **User**: A quality engineer, statistician, or validation specialist using the application
- **Confidence_Level**: The probability that a population parameter lies within a calculated interval, expressed as a percentage (typically 95%)
- **Reliability**: The proportion of conforming items in a population, expressed as a percentage
- **Allowable_Failures**: The maximum number of failures permitted in a sample while still demonstrating required reliability
- **Sample_Size**: The minimum number of units required for statistical demonstration
- **Tolerance_Factor**: A statistical multiplier used to calculate tolerance limits
- **Tolerance_Limit**: A statistical bound that contains a specified proportion of the population with stated confidence
- **Specification_Limit**: User-defined acceptance boundaries (LSL/USL) for a measured characteristic
- **Process_Performance_Index**: A capability metric (Ppk) comparing process variation to specification limits
- **Normality_Test**: Statistical test to assess if data follows a normal distribution
- **Transformation**: Mathematical operation applied to data to achieve normality
- **Back_Transformation**: Inverse operation to convert transformed results to original scale
- **Validation_Hash**: SHA-256 cryptographic hash of the calculation engine file
- **Calculation_Report**: PDF document summarizing inputs, outputs, and validation state
- **Validation_Certificate**: PDF document generated by automated test suite confirming system validation

## Requirements

### Requirement 1: Attribute Data Sample Size Calculation (Zero Failures)

**User Story:** As a quality engineer, I want to calculate the minimum sample size for attribute testing with zero allowable failures, so that I can demonstrate required reliability with specified confidence.

**Traces to:** URS-FUNC_A-01, URS-FUNC_A-02, URS-UI-04

#### Acceptance Criteria

1. WHEN a user provides Confidence_Level and Reliability values as percentages, THE System SHALL validate that both values are greater than 0 and less than or equal to 100
   - **Traces to:** URS-FUNC_A-01
2. WHEN Allowable_Failures is set to zero, THE System SHALL calculate Sample_Size using the Success Run Theorem formula: n = ceiling(ln(1-C/100) / ln(R/100))
   - **Traces to:** URS-FUNC_A-02
3. WHEN the calculation completes, THE System SHALL display the calculated Sample_Size as a positive integer
   - **Traces to:** URS-FUNC_A-02
4. IF Confidence_Level or Reliability is outside the valid range, THEN THE System SHALL display an error message and prevent calculation
   - **Traces to:** URS-FUNC_A-01

### Requirement 2: Attribute Data Sample Size Calculation (With Failures)

**User Story:** As a quality engineer, I want to calculate sample sizes when allowing a specific number of failures, so that I can use more economical sampling plans while maintaining statistical rigor.

**Traces to:** URS-FUNC_A-03, URS-FUNC_A-05

#### Acceptance Criteria

1. WHEN a user specifies Allowable_Failures greater than zero, THE System SHALL validate that the value is a non-negative integer
   - **Traces to:** URS-FUNC_A-01
2. WHEN Allowable_Failures is greater than zero, THE System SHALL calculate Sample_Size using the cumulative binomial distribution
   - **Traces to:** URS-FUNC_A-03
3. THE System SHALL iteratively solve for the smallest Sample_Size where the cumulative probability sum from k=0 to c is less than or equal to (1-Confidence_Level)
   - **Traces to:** URS-FUNC_A-03
4. WHEN the calculation completes, THE System SHALL display the calculated Sample_Size as a positive integer
   - **Traces to:** URS-FUNC_A-05

### Requirement 3: Attribute Data Sensitivity Analysis

**User Story:** As a quality engineer, I want to see sample sizes for multiple failure scenarios simultaneously, so that I can evaluate trade-offs between sample size and allowable failures.

**Traces to:** URS-FUNC_A-04, URS-FUNC_A-05

#### Acceptance Criteria

1. WHEN a user leaves the Allowable_Failures input empty, THE System SHALL automatically calculate Sample_Size for c=0, 1, 2, and 3
   - **Traces to:** URS-FUNC_A-04
2. THE System SHALL display results in a table format with two columns: Allowable_Failures and required Sample_Size
   - **Traces to:** URS-FUNC_A-04
3. WHEN a user provides a specific Allowable_Failures value, THE System SHALL calculate and display only the Sample_Size for that specific value
   - **Traces to:** URS-FUNC_A-05
4. THE System SHALL display all sensitivity analysis results simultaneously without requiring multiple user actions
   - **Traces to:** URS-FUNC_A-04

### Requirement 4: Variable Data Tolerance Factor Calculation

**User Story:** As a statistician, I want to calculate tolerance factors for normally distributed data, so that I can establish statistical tolerance limits for continuous measurements.

#### Acceptance Criteria

1. WHEN calculating one-sided tolerance limits, THE System SHALL compute the tolerance factor k1 using the non-central t-distribution formula
2. WHEN calculating two-sided tolerance limits, THE System SHALL compute the tolerance factor k2 using the Howe-Guenther approximation
3. THE System SHALL accept Sample_Size, Confidence_Level, and Reliability as inputs for tolerance factor calculation
4. THE System SHALL validate that Sample_Size is a positive integer greater than 1
5. THE System SHALL display the calculated tolerance factor with at least 4 decimal places of precision

### Requirement 5: Variable Data Tolerance Limit Calculation

**User Story:** As a quality engineer, I want to calculate tolerance limits from sample statistics, so that I can determine if a process meets specification requirements.

#### Acceptance Criteria

1. WHEN a user provides Sample_Mean, Sample_Standard_Deviation, and Tolerance_Factor, THE System SHALL calculate Upper_Tolerance_Limit as Sample_Mean + (Tolerance_Factor × Sample_Standard_Deviation)
2. WHEN calculating two-sided limits, THE System SHALL calculate Lower_Tolerance_Limit as Sample_Mean - (Tolerance_Factor × Sample_Standard_Deviation)
3. WHEN calculating one-sided limits, THE System SHALL calculate only the relevant limit (upper or lower)
4. THE System SHALL display calculated Tolerance_Limits with appropriate precision matching the input data

### Requirement 6: Specification Limit Comparison

**User Story:** As a quality engineer, I want to compare tolerance limits against specification limits, so that I can determine if a process demonstrates acceptable capability.

#### Acceptance Criteria

1. WHEN a user provides Lower_Specification_Limit and Upper_Specification_Limit, THE System SHALL validate that LSL is less than USL
2. WHEN comparing limits, THE System SHALL determine PASS status if Lower_Tolerance_Limit is greater than or equal to LSL AND Upper_Tolerance_Limit is less than or equal to USL
3. WHEN comparing limits, THE System SHALL determine FAIL status if either tolerance limit violates its corresponding specification limit
4. THE System SHALL display the comparison result as a clear PASS or FAIL indicator
5. THE System SHALL display the margin between tolerance limits and specification limits

### Requirement 7: Process Performance Index Calculation

**User Story:** As a quality engineer, I want to calculate the process performance index (Ppk), so that I can quantify process capability relative to specifications.

#### Acceptance Criteria

1. WHEN a user provides Sample_Mean, Sample_Standard_Deviation, and both specification limits, THE System SHALL calculate Ppk as the minimum of (USL - Mean)/(3×StdDev) and (Mean - LSL)/(3×StdDev)
2. WHEN only one specification limit is provided, THE System SHALL calculate Ppk using only the relevant term
3. THE System SHALL display the calculated Ppk value with at least 2 decimal places
4. THE System SHALL validate that Sample_Standard_Deviation is greater than zero before calculation

### Requirement 8: Outlier Detection

**User Story:** As a statistician, I want to detect outliers in my dataset, so that I can identify potentially anomalous data points before analysis.

#### Acceptance Criteria

1. WHEN a user provides raw data, THE System SHALL calculate the first quartile (Q1), third quartile (Q3), and interquartile range (IQR)
2. THE System SHALL flag data points as outliers if they are less than Q1 - 1.5×IQR OR greater than Q3 + 1.5×IQR
3. THE System SHALL display the count of detected outliers
4. THE System SHALL display the specific values identified as outliers
5. THE System SHALL allow the user to proceed with analysis regardless of outlier detection results

### Requirement 9: Normality Testing

**User Story:** As a statistician, I want to test if my data follows a normal distribution, so that I can determine if parametric methods are appropriate.

#### Acceptance Criteria

1. WHEN a user requests normality testing, THE System SHALL perform the Shapiro-Wilk test on the provided data
2. THE System SHALL perform the Anderson-Darling test on the provided data
3. THE System SHALL display the p-value from the Shapiro-Wilk test
4. THE System SHALL display the test statistic and critical values from the Anderson-Darling test
5. WHEN the Shapiro-Wilk p-value is less than 0.05, THE System SHALL indicate that normality is rejected
6. WHEN the Anderson-Darling statistic exceeds the critical value at alpha=0.05, THE System SHALL indicate that normality is rejected
7. THE System SHALL provide a clear interpretation of test results for non-statistical users

### Requirement 10: Probability Plot Visualization

**User Story:** As a statistician, I want to view a Q-Q plot of my data, so that I can visually assess normality and identify distribution patterns.

#### Acceptance Criteria

1. WHEN a user requests a probability plot, THE System SHALL generate a Q-Q plot comparing theoretical quantiles to sample quantiles
2. THE System SHALL display the Q-Q plot with clearly labeled axes
3. THE System SHALL include a reference line representing perfect normality
4. THE System SHALL render the plot within the application interface without requiring external tools

### Requirement 11: Data Transformation

**User Story:** As a statistician, I want to transform non-normal data, so that I can apply parametric statistical methods after achieving normality.

#### Acceptance Criteria

1. THE System SHALL offer Box-Cox transformation with automatic lambda optimization
2. THE System SHALL offer logarithmic transformation (natural log)
3. THE System SHALL offer square root transformation
4. WHEN a user selects Box-Cox transformation, THE System SHALL automatically determine the optimal lambda parameter
5. WHEN a transformation is applied, THE System SHALL store both original and transformed datasets
6. THE System SHALL validate that data is suitable for the selected transformation (e.g., all positive values for log transformation)

### Requirement 12: Post-Transformation Normality Verification

**User Story:** As a statistician, I want to verify normality after transformation, so that I can confirm the transformation was successful before proceeding with parametric analysis.

#### Acceptance Criteria

1. WHEN data is transformed, THE System SHALL automatically re-run normality tests on the transformed data
2. THE System SHALL display normality test results for both original and transformed data
3. WHEN transformed data p-value is greater than 0.05, THE System SHALL indicate that parametric methods can proceed
4. WHEN transformed data still fails normality tests, THE System SHALL recommend non-parametric methods

### Requirement 13: Back-Transformation of Results

**User Story:** As a quality engineer, I want tolerance limits calculated on transformed data to be converted back to original units, so that I can interpret results in meaningful engineering terms.

#### Acceptance Criteria

1. WHEN logarithmic transformation was used, THE System SHALL back-transform limits using the exponential function
2. WHEN Box-Cox transformation was used, THE System SHALL back-transform limits using the inverse Box-Cox formula: (lambda × value + 1)^(1/lambda)
3. WHEN square root transformation was used, THE System SHALL back-transform limits by squaring the transformed values
4. THE System SHALL display both transformed and back-transformed results
5. THE System SHALL clearly label which values are in original units versus transformed units

### Requirement 14: Non-Parametric Fallback Analysis

**User Story:** As a statistician, I want to use non-parametric methods when transformations fail, so that I can still provide statistical analysis for non-normal data.

#### Acceptance Criteria

1. WHEN all transformations fail to achieve normality, THE System SHALL automatically offer Wilks' method as a non-parametric alternative
2. WHEN using Wilks' method, THE System SHALL define tolerance limits using the minimum and maximum values of the sample
3. THE System SHALL clearly indicate when non-parametric methods are being used
4. THE System SHALL explain the limitations of non-parametric methods compared to parametric approaches

### Requirement 15: Reliability Life Testing (Zero-Failure Demonstration)

**User Story:** As a reliability engineer, I want to calculate required test duration for zero-failure demonstration, so that I can plan time-dependent reliability tests.

#### Acceptance Criteria

1. WHEN a user specifies Confidence_Level and number of failures (r=0), THE System SHALL calculate required test duration using the chi-squared distribution
2. THE System SHALL use the formula: Duration proportional to chi-squared(1-C, 2(r+1))
3. THE System SHALL display the calculated test duration or number of test units required
4. THE System SHALL validate that the number of failures is zero for this calculation method

### Requirement 16: Acceleration Factor Calculation

**User Story:** As a reliability engineer, I want to calculate acceleration factors for accelerated life testing, so that I can relate accelerated test conditions to use conditions.

#### Acceptance Criteria

1. WHEN a user provides activation energy, use temperature, and test temperature, THE System SHALL calculate the acceleration factor using the Arrhenius equation
2. THE System SHALL use the formula: AF = exp[(Ea/k) × (1/T_use - 1/T_test)]
3. THE System SHALL validate that temperatures are provided in Kelvin or convert from Celsius
4. THE System SHALL validate that test temperature is greater than use temperature
5. THE System SHALL display the calculated acceleration factor with appropriate precision

### Requirement 17: Tab-Based User Interface

**User Story:** As a user, I want different statistical methods organized in separate tabs, so that I can easily navigate to the appropriate analysis method.

#### Acceptance Criteria

1. THE System SHALL provide a tab-based layout with four tabs: "Attribute (Binomial)", "Variables (Normal)", "Non-Normal Distribution", and "Reliability"
2. WHEN a user clicks a tab, THE System SHALL display the input fields and controls specific to that analysis method
3. THE System SHALL maintain the state of inputs when switching between tabs
4. THE System SHALL clearly indicate which tab is currently active

### Requirement 18: Contextual Help and Tooltips

**User Story:** As a user, I want contextual help for statistical terms, so that I can understand what each input parameter means without external documentation.

#### Acceptance Criteria

1. THE System SHALL provide tooltips for all statistical input fields
2. WHEN a user hovers over a field label, THE System SHALL display a brief explanation of that parameter
3. THE System SHALL provide a help section at the top of the interface explaining how to select the appropriate analysis module
4. THE System SHALL use clear, non-technical language in tooltips where possible
5. THE System SHALL display all percentage inputs (Confidence_Level, Reliability) with the % symbol for clarity

### Requirement 19: Input Validation and Range Restrictions

**User Story:** As a user, I want the system to prevent invalid inputs, so that I can avoid calculation errors and receive immediate feedback.

#### Acceptance Criteria

1. THE System SHALL restrict Confidence_Level and Reliability inputs to values between 0 and 100 (percentage format)
2. THE System SHALL validate that Sample_Size inputs are positive integers
3. THE System SHALL validate that Sample_Standard_Deviation is greater than zero
4. WHEN invalid input is detected, THE System SHALL display a clear error message indicating the valid range
5. THE System SHALL prevent calculation execution until all inputs are valid

### Requirement 20: User Calculation Report Generation

**User Story:** As a quality engineer, I want to generate a PDF report of my calculations, so that I can document my analysis for regulatory compliance and quality records.

#### Acceptance Criteria

1. WHEN a user completes a calculation, THE System SHALL provide a button to generate a downloadable PDF report
2. THE Calculation_Report SHALL include the current date and time
3. THE Calculation_Report SHALL include all user inputs (Confidence_Level, Reliability, Allowable_Failures, etc.)
4. THE Calculation_Report SHALL include all calculated results (Sample_Size, Tolerance_Factors, Tolerance_Limits, Ppk, etc.)
5. THE Calculation_Report SHALL include the statistical method used
6. THE Calculation_Report SHALL include the Validation_Hash of the calculation engine file

### Requirement 21: Validation State Verification

**User Story:** As a quality manager, I want to verify that the calculation engine has not been modified since validation, so that I can ensure regulatory compliance and data integrity.

#### Acceptance Criteria

1. THE System SHALL calculate the SHA-256 hash of the calculation engine file (calculations.py)
2. THE Calculation_Report SHALL display the current engine hash with the label "Engine Hash: [HashValue]"
3. THE System SHALL compare the current engine hash against a stored validated hash
4. WHEN hashes match, THE Calculation_Report SHALL display "VALIDATED STATE: YES"
5. WHEN hashes do not match, THE Calculation_Report SHALL display "VALIDATED STATE: NO - UNVERIFIED CHANGE"
6. THE System SHALL store the validated hash in a secure configuration file

### Requirement 22: Automated Validation Report Generation

**User Story:** As a validation specialist, I want the test suite to generate a validation certificate, so that I can document IQ/OQ/PQ completion for regulatory submissions.

#### Acceptance Criteria

1. WHEN the automated test suite completes, THE System SHALL generate a PDF Validation_Certificate
2. THE Validation_Certificate SHALL include the test execution date
3. THE Validation_Certificate SHALL include the tester name or system identifier
4. THE Validation_Certificate SHALL include system information (OS, Python version, key dependency versions)
5. THE Validation_Certificate SHALL list all URS requirement IDs that were tested
6. THE Validation_Certificate SHALL display PASS or FAIL status for each tested requirement
7. THE Validation_Certificate SHALL include the final validated hash of the calculation engine

### Requirement 23: Installation Qualification

**User Story:** As a validation specialist, I want to verify that all dependencies are correctly installed with locked versions, so that I can ensure reproducible calculations across installations.

#### Acceptance Criteria

1. THE System SHALL use a hash-based lockfile (uv.lock or requirements.txt with hashes) to specify exact dependency versions
2. WHEN dependencies are installed, THE System SHALL verify that all packages match the locked versions
3. THE System SHALL provide an environment check script that confirms critical dependencies (scipy, numpy, streamlit) are at expected versions
4. WHEN dependency verification fails, THE System SHALL display a clear error message indicating which package has a version mismatch

### Requirement 24: Operational Qualification Test Suite

**User Story:** As a validation specialist, I want automated tests that verify all mathematical models, so that I can demonstrate that calculations produce correct results.

#### Acceptance Criteria

1. THE System SHALL include a pytest test suite that covers all functional requirements
2. EACH test SHALL be marked with the corresponding URS requirement ID using pytest markers (e.g., @pytest.mark.urs("URS-FUNC_A-02"))
3. THE System SHALL verify calculations against known standard values from statistical references
4. WHEN the test suite runs, THE System SHALL report which URS requirements passed and which failed
5. THE System SHALL require 100% of OQ tests to pass before generating a Validation_Certificate

### Requirement 25: Performance Qualification UI Testing

**User Story:** As a validation specialist, I want automated UI tests that simulate user workflows, so that I can verify the application functions correctly in realistic usage scenarios.

#### Acceptance Criteria

1. THE System SHALL include automated UI tests using Playwright browser automation
2. THE UI tests SHALL simulate complete user workflows: opening tabs, entering data, clicking calculate buttons, and verifying output display
3. THE UI tests SHALL verify that calculated results appear in the interface
4. THE UI tests SHALL verify that error messages display correctly for invalid inputs
5. THE System SHALL include at least one end-to-end test for each of the four analysis modules

### Requirement 26: Logging for Audit Trail

**User Story:** As a quality manager, I want important program operations to be logged, so that I can maintain an audit trail for regulatory compliance.

#### Acceptance Criteria

1. THE System SHALL log all calculation executions with timestamp, input parameters, and results
2. THE System SHALL log validation hash checks and their outcomes
3. THE System SHALL log report generation events
4. THE System SHALL log any errors or exceptions that occur during operation
5. THE System SHALL store logs in a structured format (JSON or similar) for easy parsing
6. THE System SHALL provide a configuration option to set log level (DEBUG, INFO, WARNING, ERROR)

### Requirement 27: Configuration Management

**User Story:** As a system administrator, I want to manage system configuration through environment variables and configuration files, so that I can deploy the application in different environments without code changes.

#### Acceptance Criteria

1. THE System SHALL use Pydantic Settings to read configuration from environment variables
2. THE System SHALL support configuration of: log level, validated hash value, report output directory, and application title
3. THE System SHALL provide default values for all configuration parameters
4. THE System SHALL validate configuration values at startup and display clear error messages for invalid configurations
5. THE System SHALL document all configuration parameters in a configuration guide

### Requirement 28: Extensibility for Future Modules

**User Story:** As a developer, I want the system architecture to support easy addition of new analysis modules, so that future enhancements (like Analysis of Limits) can be integrated without major refactoring.

#### Acceptance Criteria

1. THE System SHALL use a modular architecture with separate calculation modules for each analysis type
2. THE System SHALL define clear interfaces for calculation functions (inputs, outputs, error handling)
3. THE System SHALL use a plugin-like structure where new tabs can be added by creating new module files
4. THE System SHALL document the process for adding new analysis modules in the developer guide
5. THE System SHALL use consistent patterns for input validation, calculation execution, and result display across all modules
